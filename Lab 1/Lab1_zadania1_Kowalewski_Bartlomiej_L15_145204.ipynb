{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ikxh6WILYyLq"
      },
      "source": [
        "# Intro\n",
        "prowadzący: mgr inż. Dawid Wiśniewski, pokój 2.7.2 (BT), konsultacje - czwartki 15:10-16:40 (proszę o kontakt mailowy z informacją o chęci przybycia/skontaktowania się online). <br/>\n",
        "\n",
        "Zaliczenie laboratoriów:\n",
        "pokazanie przed prowadzącym wykonanych zadań laboratoryjnych w trakcie zajęć lub wysłanie ich po zakończeniu zajęć na adres e-mail dwisniewski@cs.put.poznan.pl. \n",
        "\n",
        "Laboratoria można zaliczyć bez straty punktów do momentu zakończenia kolejnych zajęć laboratoryjnych, następujących po tych na których omawiamy dany temat (czyli jeśli dziś omawiamy dany temat, wysyłając je mailowo do momentu zakończenia kolejnych zajęć). Ponieważ część z Państwa przemieszcza się między grupami laboratoryjnymi, termin ten ustalmy na moment zakończenia **ostatnich** zajęć w danym tygodniu (czwartek, 20:00).\n",
        "\n",
        "Przekroczenie tych terminów skutkuje redukcją uzyskanych punktów o 50%."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "FkjUxZnwYyLx"
      },
      "source": [
        "# Lab1: Wyrażenia regularne\n",
        "\n",
        "Poniżej znajduje się kilka przykładów konstrukcji używanych w wyrażeniach regularnych oraz przykładów tekstów które zostaną i nie zostaną dopasowane z użyciem danej konstrukcji.\n",
        "\n",
        "\n",
        "<table>\n",
        "<thead>\n",
        "    <td>Wyrażenie</td>\n",
        "    <td>Komentarz</td>\n",
        "    <td>Przykład dopasowania (<strong>pogrubiony</strong>)</td>\n",
        "    <td>Przykład niedopasowania</td>\n",
        "</thead>\n",
        "\n",
        "<tr>\n",
        "    <td>abc</td>\n",
        "    <td>zwykły ciąg znaków do wyszukania</td>\n",
        "    <td>qw<strong>abc</strong>wer</td>\n",
        "    <td>eedfds</td>\n",
        "</tr>\n",
        "<tr>\n",
        "    <td>[A-Z]</td>\n",
        "    <td>Dowolny znak z zakresu A-Z (wielka litera łacińska)</td>\n",
        "    <td><strong>A</strong>,<strong>B</strong>,<strong>C</strong>,<strong>Z</strong></td>\n",
        "    <td>1938</td>\n",
        "</tr>\n",
        "<tr>\n",
        "    <td>(abc)</td>\n",
        "    <td>Nawias okrągły tworzy grupę. \n",
        "        Grupy wykorzystywane są do specjalnego potraktowania całych podciągów, np. dopasowywania wielokrotnych powtórzeń całych sekwencji znaków. Znaki ( i ) są znakami specjalnymi, nie są wyszukiwane w tekście. Aby dopasować znak ( lub ) bez nadawania mu specjalnego znaczenia, należy poprzedzić go backslashem.</td>\n",
        "    <td><strong>abc</strong></td>\n",
        "    <td>abd</td>\n",
        "</tr>\n",
        "\n",
        "<tr>\n",
        "    <td>(kot|pies)</td>\n",
        "    <td>alternatywa - prezentuje listę możliwych wariantów dopasowań.|</td>\n",
        "    <td><strong>pies</strong>,<strong>kot</strong></td>\n",
        "    <td>koń</td>\n",
        "</tr>\n",
        "<tr>\n",
        "    <td>abc+</td>\n",
        "    <td>Znak + dopasowuje co najmniej 1 wystąpienie znaku lub grupy poprzedzającej ten znak. Większość implementacji interpretuje znaki powtórzeń w sposób zachłanny, dopasowując maksymalnie dużo znaków, tzn. jeśli na tekście \"aaaaaaa\" uruchomimy wyrażenie \"a+\", które szuka co najmniej jednego wystąpienia literki \"a\", cały ten ciąg zostanie zwrócony jako dopasowanie, ponieważ \"aaaaaaa\" jest ciągiem 7 następujących po sobie liter a.\n",
        "      <br/>abc+ - będzie dopasowywać teksty, w których literka c po sekwencji ab jest występuje co najmniej raz. <br/>a(bc)+ - dopasuje teksty, w których po literce a następuje dowolna ilość powtórzonych sekwencji liter (grupy) \"bc\", np. abcbc. <br/>ab[A-Z]+ - dopasuje teksty, w których po literkach ab nastąpi dowolna liczba wielkich liter łacińskich.\n",
        "    </td>\n",
        "    <td><strong>abccc</strong></td>\n",
        "    <td>abd</td>\n",
        "</tr>\n",
        "<tr>\n",
        "    <td>abc*</td>\n",
        "    <td>Podobnie do przykładu ze znakiem plus, jednakże znak * oznacza zero, lub więcej wystąpień (w tym przypadku literki c) </td>\n",
        "    <td><strong>ab</strong>efgh, <strong>abcc</strong>d, <strong>abc</strong></td>\n",
        "    <td>accc</td></tr>\n",
        "<tr>\n",
        "    <td>colou?r</td>\n",
        "    <td>Znak ? podobnie jak * i + działa jako wskazanie na liczbę powtórzeń poprzedzającego znaku bądź grupy. W odróżnieniu od poprzednio wymienionych jednak, znak ? oznacza, że znak/grupa \"może, ale nie musi wystąpić 1 raz\"</td>\n",
        "    <td><strong>color</strong>, <strong>colour</strong></td>\n",
        "    <td>cokolwiek innego niż w kolumnie obok</td>\n",
        "</tr>\n",
        "<tr>\n",
        "    <td>a(bc){2,4}</td>\n",
        "    <td>Tutaj również rozważamy powtórzenia poprzedniego znaku bądź grupy. pierwsza liczba w nawiasie oznacza minimalną wymaganą liczbę wystąpień znaku/grupy, druga liczba oznacza maksymalną akceptowalną liczbę wystąpien znaku/grupy. </td>\n",
        "    <td><strong>abcbcbc</strong></td>\n",
        "    <td>abc, def</td>\n",
        "</tr>\n",
        "<tr>\n",
        "    <td>.+</td>\n",
        "    <td>Znak kropki dopasowuje dowolny znak. Jeśli po nim nastąpi znak +, to wyrażenie dopasuje dowolny ciąg znaków</td>\n",
        "    <td><strong>dopasuje np. taki tekst w całości</strong></td>\n",
        "    <td></td>\n",
        "</tr>\n",
        "<tr>\n",
        "    <td>(?P&lt;nazwa&gt;abc)</td>\n",
        "    <td>Grupa nazwana - dopasowany wzorzec, np. abc zapisywany jest pod zmienną o nazwie nazwa, która może służyć do ekstrakcji fragmentów wyrażenia (patrz zad. 3)</td>\n",
        "    <td><strong>abc</strong></td>\n",
        "    <td>efg</td>\n",
        "</tr>\n",
        "<tr>\n",
        "    <td>^abc</td>\n",
        "    <td>Znacznik początku linii ^ wymaga, aby wzorzec abc został dopasowany na poczatku linii. Jeśli ciąg abc zostanie napotkany w dalszej części tekstu - nie zostanie dopasowany</td>\n",
        "    <td><strong>abc</strong>dabc</td>\n",
        "    <td>dabc</td>\n",
        "</tr>\n",
        "<tr>\n",
        "    <td>abc\\$</td>\n",
        "    <td>Znacznik końca linii \\$ wymaga, aby wzorzec abc został dopasowany na końcu linii. Jeśli ciąg abc zostanie napotkany we wcześniejszej części tekstu - nie zostanie dopasowany</td>\n",
        "    <td>abcd<strong>abc</strong></td>\n",
        "    <td>abcd</td>\n",
        "</tr>\n",
        "<tr>\n",
        "    <td>\\babc\\b</td>\n",
        "    <td>Tzw. 'word boundary', Jeśli dany wzorzec otoczymy znakami specjalnymi \\b - wzorzec zostanie dopasowany jedynie w przypadku, kiedy bezpośrednio przed i za wzorcem nie ma liter (innymi słowy word boundary zapewnia, że dopasujemy całe słowa, a nie podciągi słów</td>\n",
        "    <td><strong>abc</strong> defabc</td><td>abcdef</td></tr>\n",
        "</table>\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "avSgUXAfYyL2"
      },
      "source": [
        "Przykłady powyżej ilustrują nam, że niektóre znaki, takie jak litery i cyfry są interpretowane przez wyrażenia regularne jako zwykłe znaki. Inne natomiast mają specjalne znaczenie (np.: .*?{}()-^\\$). Czasem jednak chcielibyśmy, aby któryś ze znaków specjalnych został potraktowany tak jak zwykły znak, gdyż chcielbyśmy dopasować np. znak gwiazki. Aby sprawić, że znak specjalny będzie interpretowany jako zwykły - należy poprzedzić wystąpienie tego znaku backslashem. (np.: \\\\+)\n",
        "\n",
        "Przykłady ciekawych wyrażeń regularnych:\n",
        "<ul>\n",
        "    <li>Parsowanie przykładowego hasła na stronie: ^[a-z0-9_]{6,18}\\$; - wymagaj, aby tekst (linia) zaczynał sie(^) od ciągu od 6 do 18 wystąpień ({6,18}) znaków, które należą do zbioru - małych liter(a-z), cyfr(0-9) i podkreślników. Po takiej sekwencji nastąpić powinien koniec tekstu (linii) (`$`). Przykład dopasującego się tekstu: <strong>a8dccc__2</strong></li>\n",
        "    <li>Ekstakcja kodów kolorów, zapisanych w postaci heksadecymalnej: \\b#[0-9a-fA-F]{6}\\b - dopasuj ciąg rozpoczynający się znakiem \"płotek\" (#), po którym nastąpi 6 znaków, spośród których każdy jest cyfrą, małą literą z zakresu a-f lub wielką literą z zakresu A-F. Ciąg nie może być podciągiem istniejącego ciągu liter (\\b), tylko odrębnym słowem. Przykład dopasowania: <strong>#AABB4C</strong>\n",
        "</ul>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "p_wkjnM-YyL3"
      },
      "source": [
        "# Zadadnie 1 (1 punkt): Proste wyrażenia regularne\n",
        "\n",
        "<div class=\"alert alert-block alert-info\">Stwórz wyrażenie regularne (przypisz do zmiennej REGEX jedno wyrażenie), które dopasuje wszystkie wyrazy zaczynające się z wielkiej litery, będące długości co najmniej 4, a co najwyżej 6 znaków. Dopasowany tekst powinien: \n",
        "<ol>\n",
        "       <li> Posiadać jedną wielką literę (początkową). </li>\n",
        "       <li> Każda kolejna litera powinna być małą literą. </li>\n",
        "       <li> Dopasowany tekst nie powinien zawierać znaków innych niż litery. </li>\n",
        "</ol>\n",
        "</div>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-bsYLAjkYyL4"
      },
      "source": [
        "<div class=\"alert alert-block alert-success\">\n",
        "<strong>Oczekiwany rezultat:</strong> <br/>\n",
        "dopasowano: Anna <br/>\n",
        "dopasowano: Reddit\n",
        "</div>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "1nmmpFzqYyL5",
        "outputId": "996f8b42-8065-46ea-b4a8-ca7ef7dc3720"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "dopasowano: Anna\n",
            "dopasowano: Reddit\n"
          ]
        }
      ],
      "source": [
        "# Zadanie 1\n",
        "import re\n",
        "\n",
        "test_words = ['zebra', 'krowa', 'Bitcoin', 'Anna', 'Peer2Peer', 'Reddit']\n",
        "\n",
        "REGEX = r'^[A-Z][a-z]{3,5}$'  # tu stwórz wyrażenie regularne np r'test'\n",
        "\n",
        "for word in test_words:\n",
        "    if re.search(REGEX, word):\n",
        "        print(\"dopasowano: {w}\".format(w=word))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "XHX6jAKUYyL7"
      },
      "source": [
        "---\n",
        "# Zadanie 2 (1 punkt): Czyszczenie tekstu\n",
        "<div class=\"alert alert-block alert-info\">Utwórz wyrażenie regularne w zmiennej REGEX(jedno), z użyciem którego dopasujemy tagi HTML, które zostaną usunięte z użyciem funkcji re.sub. <br/>Funkcja re.sub (substitute) przyjmuje trzy parametry: \n",
        "    <ol>\n",
        "           <li>Jaki wzorzec powinien zostać dopasowany w celu podmiany na inny tekst.</li>\n",
        "           <li>Czym podmienić dopasowania (w naszym przypadku pusty ciąg znaków, gdyż chcemy usunąć tagi). </li>\n",
        "           <li>Zmienną zawierającą tekst, w którym będziemy szukać.</li>\n",
        "    </ol>\n",
        "           \n",
        "<strong>Wskazówka:</strong> Domyślnie, wyrażenia regularne działają zachłannie, tzn. próbują dopasować jak najdłuższy możliwy tekst. Dla wyrażenia a.\\*a i tekstu: \"analfabeta\" dopasowany zostanie cały tekst - ciąg .\\* dopasuje najdłuższą możliwą sekwencję znaków, po której następuje literka a i która poprzedzona jest literką a. <br/>\n",
        "Można jednak zmodyfikować to wyrażenie tak, aby poszukać najkrótszych możliwych (rozłącznych) ciągów, które opisane są przez wzorzec. W naszym przykładzie będzie to: ana oraz abeta. Aby to osiągnąć, po znaku gwiazdki musimy dodać znak zapytania: a.\\*?a we wzorcu.\n",
        "</div>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "08EFiDKDYyL7"
      },
      "source": [
        "<div class=\"alert alert-block alert-success\">\n",
        "    <strong>Oczekiwany rezultat:</strong> <br/>\n",
        "1. To jest tytul 2. A to - Link do google.\n",
        "</div>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "qg5soMpJYyL8",
        "outputId": "37be8fe0-6411-49a4-bd51-0164d96b54f3"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "1. To jest tytul 2. A to - link do google.\n"
          ]
        }
      ],
      "source": [
        "# Zadanie 2\n",
        "import re\n",
        "html_text = \"<h1>1. To jest tytul </h1><ul><li class='link'><a href='www.google.pl'>2. A to - link do google.</a></li></ul>\"\n",
        "\n",
        "REGEX = r'<.*?>'   # tu wpisz wyrażenie\n",
        "\n",
        "print(re.sub(REGEX, '', html_text))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "NjGOuIyYYyL9"
      },
      "source": [
        "---\n",
        "\n",
        "# Zadanie 3 (1 punkt): Ekstrakcja informacji\n",
        "\n",
        "<div class=\"alert alert-block alert-info\">Wykorzystując mechanizm grup nazwanych (patrz tabelka na początku dokumentu), napisz wyrażenie regularne, które z zadanego adresu url wyekstrahuje nazwy zmiennych oraz ich wartości (wzorce typu ?nazwa_zmiennej=wartosc_zmiennej). Częścią zadania jest stworzenie dwóch grup nazwanych - pierwsza powinna otrzymać nazwę \"name\", druga zaś \"val\". Nazwy te wykorzystane są później przy wyświetlaniu wyników (patrz: funkcja print). <br/>\n",
        "Uznajmy, że nazwą zmiennej oraz wartością może być dowolny ciąg liter oraz cyfr.</div>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "no33rMEKYyL-"
      },
      "source": [
        "<div class=\"alert alert-block alert-success\">\n",
        "<strong>Oczekiwany rezultat:</strong> <br/>\n",
        "Variable name: id, value: 1254 <br/>\n",
        "Variable name: name, value: Mike <br/>\n",
        "Variable name: surname, value: Tyson <br/>\n",
        "</div>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "id": "JGTPPdgDYyL-",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "9210c44a-e3ae-4f48-cbef-c865da8b2e8d"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Variable name: id, value: 1254\n",
            "Variable name: name, value: Mike\n",
            "Variable name: surname, value: Tyson\n"
          ]
        }
      ],
      "source": [
        "# Zadanie 3\n",
        "import re\n",
        "\n",
        "url = \"http://html.net/page.php?id=1254?name=Mike?surname=Tyson\"\n",
        "\n",
        "REGEX = r'\\?(?P<name>[a-zA-Z0-9]+)\\=(?P<val>[a-zA-Z0-9]+)'\n",
        "\n",
        "for match in re.finditer(REGEX, url):\n",
        "    print(\"Variable name: {name}, value: {val}\".format(\n",
        "        name=match.group('name'), val=match.group('val')\n",
        "    ))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "bZTX0wvgYyL_"
      },
      "source": [
        "---\n",
        "\n",
        "# Zadanie 4 (2 punkty): Niejednoznaczny tekst\n",
        "\n",
        "<div class=\"alert alert-block alert-info\">\n",
        "Największa trudność w przetwarzaniu języka wynika z faktu, że język jest często wieloznaczny. Dla przykładu: kropka nie zawsze oznacza koniec zdania, czasem jest częścią np. skrótu. Dla przykładowego tekstu zaproponowano wyrażenie regularne, które można zinterpretować w następujący sposób: \n",
        "\n",
        "<br/>\n",
        "\n",
        "Dopasuj wszystkie ciągi znaków zakończone kropką (niezachłannie [patrz wskazówka do zadania 2], szukamy \"najbliższej\" kropki). Następnie używamy mechanizmu \"positive lookahead\" https://www.regular-expressions.info/lookaround.html, aby podejrzeć jaki tekst występuje za kropką. Jeśli za kropką widzimy jeden z ciągów: \n",
        "<ul>\n",
        "<li>spacja, dowolna litera</li>\n",
        "<li>koniec tekstu </li>\n",
        "</ul>\n",
        "to uznajemy tę kropkę za koniec zdania.\n",
        "<br/>\n",
        "Tekst dopasowany przez positive lookahead nie stanowi części dopasowania, jest tylko weryfikacją, czy to, co znajduje się po dopasowaniu pozwala nam zatwierdzić decyzję czy nie (jeśli po kropce nie dopasuje się positive lookahead, wyrażenie nie wykryje tam końca zdania).\n",
        "\n",
        "<br/>\n",
        "<strong>Zadanie (a) (1 punkt)</strong>: Spróbuj zmodyfikować to wyrażenie tak, aby dopasowywało pełne, poprawne zdania. Czy udało się poprawnie podzielić tekst?<br/>\n",
        "<strong>Zaliczenie zadania</strong>: zmodyfikować wyrażanie tak, aby poprawnie podzielił on zadany tekst na zdania (bez listowania wsystkich napotkanych skrótów jako część wyrażenia!), bądź napisanie wyjaśnienia dlaczego podejście oparte o wyrażenia się nie sprawdzi jako komentarz w kodzie.\n",
        "</div>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "id": "jcSzmmK0YyMA",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "c56d4d54-5431-4eb0-eed1-ebb5de9f8cd9"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Dear Mr.\n",
            " Nowak, I would like to invite you to a conference in the U.S.A.\n",
            " The conference will start on Wed. the 7th of March and will end on Sat. 10 of March.\n",
            " The conference location is Warsaw, Poland.\n",
            " The keynote speaker will be M.D.\n",
            " Obama.\n"
          ]
        }
      ],
      "source": [
        "import re\n",
        "\n",
        "text = \"Dear Mr. Nowak, I would like to invite you to a conference in the U.S.A. The conference will start on Wed. the 7th of March and will end on Sat. 10 of March. The conference location is Warsaw, Poland. The keynote speaker will be M.D. Obama.\"\n",
        "\n",
        "REGEX = r'.*?\\.(?=( [A-Z]|$))' \n",
        "# Objaśnienie wyrażenia z REGEX:\n",
        "# dopasuj najkrótszy tekst, po którym występuje kropka (tak, aby nie dopasować wszystkich zdan naraz poprzez użycie .*). \n",
        "# Podejrzyj (wykorzystując positive-lookahead) czy po kropce występuje spacja oraz Wielka litera bądź koniec tekstu - jeśli tak - mamy zdanie!\n",
        "\n",
        "for match in re.finditer(REGEX, text):\n",
        "    print(match.group(0))\n",
        "\n",
        "# W tym zadaniu podejście oparte o wyrażenia regularne nie sprawdzi się, gdyż skróty zakończone kropką występują zarówno na końcu, jak i w środku zdania, \n",
        "# co powoduje, że mimo dobrego dopasowania do wzorca, program, nie rozpoznając skrótu w środku zdania, błędnie dzieli tekst na pojedyncze zdania. \n",
        "# W przypadku podania znanych skrótów do wyrażenia regularnego program poradziłby sobie z tym problemem."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "pok2CVNkYyMA"
      },
      "source": [
        "<div class=\"alert alert-block alert-info\">\n",
        "Zadań tak powtarzalnych jak podział tekstu na zdania, słowa itp. zazwyczaj nie implementuje się od \"zera\". Istnieją narzędzia, które są szeroko wykorzystywane do przetwarzania języka, np:\n",
        "<ul>\n",
        "    <li>SpaCy - https://spacy.io - stosunkowo nowe, zyskujące na popularności narzędzie. Wiele rzeczy działa dobrze bez zbędnej konfiguracji</li>\n",
        "    <li>NLTK - http://www.nltk.org - bardzo dojrzałe narzędzie wykorzystywane głównie do celów naukowych, zawierające wiele korpusów tekstowych.\n",
        "</ul>\n",
        "Zarówno SpaCy jak i NLTK zawierają narzędzia pozwalające na rozwiązanie większości podstawowych problemów przetwarzania języka (tokenizacja, podział na zdania, POS-tagging, wykrywanie encji nazwanych (NER) i inne).\n",
        "<br/>\n",
        "    <strong>Zadanie (b) (1 punkt)</strong>: Korzystając z dokumentacji, spróbuj podzielić na zdania zadany tekst z użyciem zarówno NLTK jak i SpaCy (fraza-klucz: \"sentence splitting\"). \n",
        "<br/>Które narzędzie poradziło sobie lepiej? Czy oba/którekolwiek narzędzie wykonało to zadanie popranie? (Pamiętajmy, że zdania takie jak zadane są bardzo specyficznymi przykładami, mającymi pokazać trudność procedury - zazwyczaj narzędzia radzą sobie naprawdę dobrze). <br/>\n",
        "    <strong>Zaliczenie zadania</strong>: poprawne wykorzystanie funkcji do podziału tekstu z obu bibliotek i wyświetlenie poszczególnych zdań w osobnych linijkach. Jakość podziału nie jest oceniana.\n",
        "    \n",
        "<strong>UWAGA: Jeśli na komputerze z którego korzystasz nie udało się załadować modelu SpaCy, wykonaj zadanie jedynie z użyciem NLTK. </strong>\n",
        "</div>"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import nltk\n",
        "nltk.download('punkt')\n",
        "text = \"Dear Mr. Nowak, I would like to invite you to a conference in the U.S.A. The conference will start on Wed., the 7th of March and will end on Sat., the 10th of March. The conference location is Warsaw, Poland. The keynote speaker will be M.D. Mark Obama.\"\n",
        "nltk.sent_tokenize(text)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "3Nov2eTMNhwY",
        "outputId": "c77a0176-1f42-4740-a0e1-bfec78e2c391"
      },
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[nltk_data] Downloading package punkt to /root/nltk_data...\n",
            "[nltk_data]   Package punkt is already up-to-date!\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['Dear Mr. Nowak, I would like to invite you to a conference in the U.S.A.',\n",
              " 'The conference will start on Wed., the 7th of March and will end on Sat., the 10th of March.',\n",
              " 'The conference location is Warsaw, Poland.',\n",
              " 'The keynote speaker will be M.D.',\n",
              " 'Mark Obama.']"
            ]
          },
          "metadata": {},
          "execution_count": 6
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {
        "id": "hKuK5oLDYyMB",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "0d9ee5da-9f31-4625-b44a-5ee395f8aca0"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/requests/__init__.py:91: RequestsDependencyWarning: urllib3 (1.26.8) or chardet (3.0.4) doesn't match a supported version!\n",
            "  RequestsDependencyWarning)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Dear Mr. Nowak, I would like to invite you to a conference in the U.S.A.\n",
            "The conference will start on Wed., the 7th of March and will end on Sat., the 10th of March.\n",
            "The conference location is Warsaw, Poland.\n",
            "The keynote speaker will be M.D. Mark Obama.\n"
          ]
        }
      ],
      "source": [
        "import spacy\n",
        "nlp = spacy.load('en_core_web_sm')\n",
        "text = \"Dear Mr. Nowak, I would like to invite you to a conference in the U.S.A. The conference will start on Wed., the 7th of March and will end on Sat., the 10th of March. The conference location is Warsaw, Poland. The keynote speaker will be M.D. Mark Obama.\"\n",
        "text_sentences = nlp(text)\n",
        "for sentence in text_sentences.sents:\n",
        "    print(sentence.text)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ByDj9wfEYyMC"
      },
      "source": [
        "---\n",
        "\n",
        "# Zadanie 5 (0 punktów, ale ciekawe): Wyszukiwanie naiwne vs REGEX - czas działania\n",
        "\n",
        "<div class=\"alert alert-block alert-info\">\n",
        "Kiedy wykorzystujemy wzorzec wyrażenia regularnego, zostaje on zamieniony z postaci tekstowej na odpowiedni automat w pamięci. Proces takiej zamiany nazywamy kompilacją. <br/>Jeśli dane wyrażenie regularne jest często wykorzystywane, dobrą praktyką jest, aby skompilować je raz do postaci automatu - następnie używać wersji skompilowanej (patrz użycie <strong>re.compile()</strong> w zadaniu). Jeśli nie skompilujemy wyrażenia i użyjemy go w formie tekstowej (jak w poprzednich zadaniach) - każde wykorzystanie wyrażenia spowoduje przebudowanie automatu. <br/>\n",
        "W poniższym kodzie porównujemy dwie metody wyszukiwania w tekście. W dużym korpusie tekstowym (biblia), chcielibyśmy sprawdzić jakie imiona męskie i żeńskie występują w księdze. W tym celu stworzono listę 2000 najczęściej nadawanych imion w 2017 roku w USA (zapisanej w liście: names) i użyto dwóch metod:\n",
        "<ol>\n",
        "    <li>Naiwnej, w której iterujemy po imionach i sprawdzamy, które z nich występują w tekście</li>\n",
        "    <li>Opartej o wyrażenie regularne, w którym jeden automat wyszukuje wszystkie imiona w jednym przebiegu. </li>\n",
        "</ol>\n",
        "\n",
        "W tym zadaniu nie trzeba pisać kodu, po prostu przeanalizuj kod, następnie uruchom go i zaobswerwuj różnicę :)\n",
        "</div>"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install s3fs"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "24C9XzuFWX94",
        "outputId": "c1b0e8fa-46b8-4256-c056-2c18e240f92f"
      },
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting s3fs\n",
            "  Downloading s3fs-2022.2.0-py3-none-any.whl (26 kB)\n",
            "Collecting fsspec==2022.02.0\n",
            "  Downloading fsspec-2022.2.0-py3-none-any.whl (134 kB)\n",
            "\u001b[K     |████████████████████████████████| 134 kB 6.2 MB/s \n",
            "\u001b[?25hCollecting aiohttp<=4\n",
            "  Downloading aiohttp-3.8.1-cp37-cp37m-manylinux_2_5_x86_64.manylinux1_x86_64.manylinux_2_12_x86_64.manylinux2010_x86_64.whl (1.1 MB)\n",
            "\u001b[K     |████████████████████████████████| 1.1 MB 33.1 MB/s \n",
            "\u001b[?25hCollecting aiobotocore~=2.1.0\n",
            "  Downloading aiobotocore-2.1.2.tar.gz (58 kB)\n",
            "\u001b[K     |████████████████████████████████| 58 kB 6.9 MB/s \n",
            "\u001b[?25hCollecting botocore<1.23.25,>=1.23.24\n",
            "  Downloading botocore-1.23.24-py3-none-any.whl (8.4 MB)\n",
            "\u001b[K     |████████████████████████████████| 8.4 MB 52.5 MB/s \n",
            "\u001b[?25hRequirement already satisfied: wrapt>=1.10.10 in /usr/local/lib/python3.7/dist-packages (from aiobotocore~=2.1.0->s3fs) (1.13.3)\n",
            "Collecting aioitertools>=0.5.1\n",
            "  Downloading aioitertools-0.10.0-py3-none-any.whl (23 kB)\n",
            "Collecting yarl<2.0,>=1.0\n",
            "  Downloading yarl-1.7.2-cp37-cp37m-manylinux_2_5_x86_64.manylinux1_x86_64.manylinux_2_12_x86_64.manylinux2010_x86_64.whl (271 kB)\n",
            "\u001b[K     |████████████████████████████████| 271 kB 72.8 MB/s \n",
            "\u001b[?25hCollecting aiosignal>=1.1.2\n",
            "  Downloading aiosignal-1.2.0-py3-none-any.whl (8.2 kB)\n",
            "Collecting multidict<7.0,>=4.5\n",
            "  Downloading multidict-6.0.2-cp37-cp37m-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (94 kB)\n",
            "\u001b[K     |████████████████████████████████| 94 kB 3.7 MB/s \n",
            "\u001b[?25hRequirement already satisfied: charset-normalizer<3.0,>=2.0 in /usr/local/lib/python3.7/dist-packages (from aiohttp<=4->s3fs) (2.0.12)\n",
            "Requirement already satisfied: typing-extensions>=3.7.4 in /usr/local/lib/python3.7/dist-packages (from aiohttp<=4->s3fs) (3.10.0.2)\n",
            "Requirement already satisfied: attrs>=17.3.0 in /usr/local/lib/python3.7/dist-packages (from aiohttp<=4->s3fs) (21.4.0)\n",
            "Collecting async-timeout<5.0,>=4.0.0a3\n",
            "  Downloading async_timeout-4.0.2-py3-none-any.whl (5.8 kB)\n",
            "Collecting frozenlist>=1.1.1\n",
            "  Downloading frozenlist-1.3.0-cp37-cp37m-manylinux_2_5_x86_64.manylinux1_x86_64.manylinux_2_17_x86_64.manylinux2014_x86_64.whl (144 kB)\n",
            "\u001b[K     |████████████████████████████████| 144 kB 86.3 MB/s \n",
            "\u001b[?25hCollecting asynctest==0.13.0\n",
            "  Downloading asynctest-0.13.0-py3-none-any.whl (26 kB)\n",
            "Collecting typing-extensions>=3.7.4\n",
            "  Downloading typing_extensions-4.1.1-py3-none-any.whl (26 kB)\n",
            "Collecting urllib3<1.27,>=1.25.4\n",
            "  Downloading urllib3-1.26.8-py2.py3-none-any.whl (138 kB)\n",
            "\u001b[K     |████████████████████████████████| 138 kB 80.5 MB/s \n",
            "\u001b[?25hRequirement already satisfied: python-dateutil<3.0.0,>=2.1 in /usr/local/lib/python3.7/dist-packages (from botocore<1.23.25,>=1.23.24->aiobotocore~=2.1.0->s3fs) (2.8.2)\n",
            "Collecting jmespath<1.0.0,>=0.7.1\n",
            "  Downloading jmespath-0.10.0-py2.py3-none-any.whl (24 kB)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.7/dist-packages (from python-dateutil<3.0.0,>=2.1->botocore<1.23.25,>=1.23.24->aiobotocore~=2.1.0->s3fs) (1.15.0)\n",
            "Requirement already satisfied: idna>=2.0 in /usr/local/lib/python3.7/dist-packages (from yarl<2.0,>=1.0->aiohttp<=4->s3fs) (2.10)\n",
            "Building wheels for collected packages: aiobotocore\n",
            "  Building wheel for aiobotocore (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for aiobotocore: filename=aiobotocore-2.1.2-py3-none-any.whl size=55992 sha256=c4eef4029b9c75a0947018c5c1e8d6bd670fc201e7f330ddbef4edc1937072df\n",
            "  Stored in directory: /root/.cache/pip/wheels/0e/9e/81/732cf36b7a7e73f82ef7793b779210f0bf94e12c13b3f2a18e\n",
            "Successfully built aiobotocore\n",
            "Installing collected packages: typing-extensions, multidict, frozenlist, yarl, urllib3, jmespath, asynctest, async-timeout, aiosignal, botocore, aioitertools, aiohttp, fsspec, aiobotocore, s3fs\n",
            "  Attempting uninstall: typing-extensions\n",
            "    Found existing installation: typing-extensions 3.10.0.2\n",
            "    Uninstalling typing-extensions-3.10.0.2:\n",
            "      Successfully uninstalled typing-extensions-3.10.0.2\n",
            "  Attempting uninstall: urllib3\n",
            "    Found existing installation: urllib3 1.24.3\n",
            "    Uninstalling urllib3-1.24.3:\n",
            "      Successfully uninstalled urllib3-1.24.3\n",
            "\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
            "tensorflow 2.8.0 requires tf-estimator-nightly==2.8.0.dev2021122109, which is not installed.\n",
            "requests 2.23.0 requires urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1, but you have urllib3 1.26.8 which is incompatible.\n",
            "datascience 0.10.6 requires folium==0.2.1, but you have folium 0.8.3 which is incompatible.\n",
            "arviz 0.11.4 requires typing-extensions<4,>=3.7.4.3, but you have typing-extensions 4.1.1 which is incompatible.\u001b[0m\n",
            "Successfully installed aiobotocore-2.1.2 aiohttp-3.8.1 aioitertools-0.10.0 aiosignal-1.2.0 async-timeout-4.0.2 asynctest-0.13.0 botocore-1.23.24 frozenlist-1.3.0 fsspec-2022.2.0 jmespath-0.10.0 multidict-6.0.2 s3fs-2022.2.0 typing-extensions-4.1.1 urllib3-1.26.8 yarl-1.7.2\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.colab-display-data+json": {
              "pip_warning": {
                "packages": [
                  "urllib3"
                ]
              }
            }
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {
        "id": "JOBbheMDYyMC",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "f79ad5ed-fc08-41e8-f787-d7eb92696aa0"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[nltk_data] Downloading package gutenberg to /root/nltk_data...\n",
            "[nltk_data]   Package gutenberg is already up-to-date!\n",
            "Czas wyszukiwania naiwnego: 7.55192275599984.\n",
            "Czas kompilacji wyrażenia 0.03886465400000816. Czas wyszukiwania z wyrażeniem 1.1910469130002639\n",
            "Z regexami 6.340575399315247 razy szybciej!\n"
          ]
        }
      ],
      "source": [
        "import nltk                                            # stąd pobierzemy zbiór tekstowy (korpus)\n",
        "nltk.download('gutenberg')\n",
        "from timeit import default_timer as timer              # funkcja potrzebna do mierzenia czasu\n",
        "\n",
        "raw_bible = nltk.corpus.gutenberg.raw('bible-kjv.txt') # wczytaj tekst biblii\n",
        "\n",
        "try:\n",
        "    names = open('names.txt', 'r').read().split(\"\\n\")      # wczytaj listę imion w formie listy pythonowej ['adam', 'ania', ...]\n",
        "except:\n",
        "    # jesli nie ma pliku lokalnie, sprobuj wczytac z Amazon S3 (potrzebne jesli korzystasz z GoogleColab)\n",
        "    import pandas\n",
        "    import s3fs\n",
        "    df = pandas.read_csv(\"https://dwisniewski-put-pjn.s3.eu-north-1.amazonaws.com/names.txt\", header=None)\n",
        "    names = [name[0] for name in df.values.tolist()]\n",
        "\n",
        "names_found_naive = []\n",
        "names_found_regex = []\n",
        "\n",
        "# METODA NAIWNA\n",
        "start_naive = timer()\n",
        "for name in names:                       # dla każdego wcztanego imienia (z 1000 imion)\n",
        "    if name in raw_bible:                # sprawdz czy tekst imienia występuje w biblii (ciągu znaków)\n",
        "        names_found_naive.append(name)   # jeśli tak to dopisz do listy\n",
        "end_naive = timer()\n",
        "\n",
        "print(\"Czas wyszukiwania naiwnego: {diff}.\".format(diff=end_naive-start_naive))\n",
        "\n",
        "####################################################################################\n",
        "\n",
        "# METODA OPARTA O REGEX\n",
        "start_regex = timer()\n",
        "REGEX = '(' + '|'.join(names) + ')'      # tworzy wielką alternatywę imion: (adam|ania|...) - która reprezentowana jest jako drzewo prefiksowe\n",
        "compiled = re.compile(REGEX)\n",
        "start_compiled = timer()\n",
        "for match in compiled.finditer(raw_bible):\n",
        "    names_found_regex.append(match.groups(0))\n",
        "end_regex = timer()\n",
        "\n",
        "print(\"Czas kompilacji wyrażenia {comp}. Czas wyszukiwania z wyrażeniem {search}\".format(comp=start_compiled-start_regex, search=end_regex-start_compiled))\n",
        "print(\"Z regexami {n} razy szybciej!\".format(n=(1.*end_naive-start_naive)/(end_regex-start_compiled)))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "OkDpV3RdYyMD"
      },
      "source": [
        "\n",
        "\n",
        "---\n",
        "\n",
        "# Ciekawe materiały:\n",
        "Jeśli zainteresowały was wyrażenia regularne i chcielibyście je bardziej zgłębić, oto garść ciekawych linków:\n",
        "<ol>\n",
        "<li>https://regexone.com - Przystępny kurs wyrażeń regularnych z zadaniami</li>\n",
        "<li>https://regexcrossword.com - Ciekawy zbiór zadań w formie krzyżówek, zdarzają się trudne :)</li>\n",
        "    <li>https://www.rexegg.com/regex-explosive-quantifiers.html - wyrażenia regularne mogą działać NAPRAWDĘ długo</li>\n",
        "</ol>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ebzXn85_YyME"
      },
      "outputs": [],
      "source": [
        ""
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.8.5"
    },
    "colab": {
      "name": "Lab1_zadania1_Kowalewski_Bartlomiej_L15_145204.ipynb",
      "provenance": []
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}