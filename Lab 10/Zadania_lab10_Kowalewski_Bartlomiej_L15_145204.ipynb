{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Zadania_lab10_Kowalewski_Bartlomiej_L15_145204.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "# Wykrywanie encji nazwanych z Flair\n",
        "\n",
        "To już ostatnie laboratoria zadaniowe, w związku z tym, jeśli znajdziecie chwilę wolnego czasu, wypełnijcie proszę ankietę: https://docs.google.com/forms/d/1rHPjpL70XdXRD-ILl3AHophPNUk0AhsFus1-mtkUPsI\n",
        "\n",
        "Pozwoli to mi poprawić laboratoria w przyszłości, z góry dziękuję :)\n",
        "\n",
        "# Flair\n",
        "\n",
        "Biblioteka Flair to bardzo popularne narzędzie do tagowania sekwencji. Zaintstalujmy ją"
      ],
      "metadata": {
        "id": "OcjJ-YZy5-Pl"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install flair"
      ],
      "metadata": {
        "id": "4inJhzI0wQmM",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "64baab32-88bf-4230-89c8-12fe3ee2f818"
      },
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Collecting flair\n",
            "  Downloading flair-0.11.3-py3-none-any.whl (401 kB)\n",
            "\u001b[?25l\r\u001b[K     |▉                               | 10 kB 18.7 MB/s eta 0:00:01\r\u001b[K     |█▋                              | 20 kB 25.9 MB/s eta 0:00:01\r\u001b[K     |██▌                             | 30 kB 32.2 MB/s eta 0:00:01\r\u001b[K     |███▎                            | 40 kB 26.9 MB/s eta 0:00:01\r\u001b[K     |████                            | 51 kB 21.4 MB/s eta 0:00:01\r\u001b[K     |█████                           | 61 kB 24.2 MB/s eta 0:00:01\r\u001b[K     |█████▊                          | 71 kB 23.0 MB/s eta 0:00:01\r\u001b[K     |██████▌                         | 81 kB 24.6 MB/s eta 0:00:01\r\u001b[K     |███████▍                        | 92 kB 26.6 MB/s eta 0:00:01\r\u001b[K     |████████▏                       | 102 kB 28.3 MB/s eta 0:00:01\r\u001b[K     |█████████                       | 112 kB 28.3 MB/s eta 0:00:01\r\u001b[K     |█████████▉                      | 122 kB 28.3 MB/s eta 0:00:01\r\u001b[K     |██████████▋                     | 133 kB 28.3 MB/s eta 0:00:01\r\u001b[K     |███████████▍                    | 143 kB 28.3 MB/s eta 0:00:01\r\u001b[K     |████████████▎                   | 153 kB 28.3 MB/s eta 0:00:01\r\u001b[K     |█████████████                   | 163 kB 28.3 MB/s eta 0:00:01\r\u001b[K     |█████████████▉                  | 174 kB 28.3 MB/s eta 0:00:01\r\u001b[K     |██████████████▊                 | 184 kB 28.3 MB/s eta 0:00:01\r\u001b[K     |███████████████▌                | 194 kB 28.3 MB/s eta 0:00:01\r\u001b[K     |████████████████▎               | 204 kB 28.3 MB/s eta 0:00:01\r\u001b[K     |█████████████████▏              | 215 kB 28.3 MB/s eta 0:00:01\r\u001b[K     |██████████████████              | 225 kB 28.3 MB/s eta 0:00:01\r\u001b[K     |██████████████████▊             | 235 kB 28.3 MB/s eta 0:00:01\r\u001b[K     |███████████████████▋            | 245 kB 28.3 MB/s eta 0:00:01\r\u001b[K     |████████████████████▍           | 256 kB 28.3 MB/s eta 0:00:01\r\u001b[K     |█████████████████████▏          | 266 kB 28.3 MB/s eta 0:00:01\r\u001b[K     |██████████████████████          | 276 kB 28.3 MB/s eta 0:00:01\r\u001b[K     |██████████████████████▉         | 286 kB 28.3 MB/s eta 0:00:01\r\u001b[K     |███████████████████████▋        | 296 kB 28.3 MB/s eta 0:00:01\r\u001b[K     |████████████████████████▌       | 307 kB 28.3 MB/s eta 0:00:01\r\u001b[K     |█████████████████████████▎      | 317 kB 28.3 MB/s eta 0:00:01\r\u001b[K     |██████████████████████████      | 327 kB 28.3 MB/s eta 0:00:01\r\u001b[K     |███████████████████████████     | 337 kB 28.3 MB/s eta 0:00:01\r\u001b[K     |███████████████████████████▊    | 348 kB 28.3 MB/s eta 0:00:01\r\u001b[K     |████████████████████████████▌   | 358 kB 28.3 MB/s eta 0:00:01\r\u001b[K     |█████████████████████████████▍  | 368 kB 28.3 MB/s eta 0:00:01\r\u001b[K     |██████████████████████████████▏ | 378 kB 28.3 MB/s eta 0:00:01\r\u001b[K     |███████████████████████████████ | 389 kB 28.3 MB/s eta 0:00:01\r\u001b[K     |███████████████████████████████▉| 399 kB 28.3 MB/s eta 0:00:01\r\u001b[K     |████████████████████████████████| 401 kB 28.3 MB/s \n",
            "\u001b[?25hCollecting segtok>=1.5.7\n",
            "  Downloading segtok-1.5.11-py3-none-any.whl (24 kB)\n",
            "Collecting sqlitedict>=1.6.0\n",
            "  Downloading sqlitedict-2.0.0.tar.gz (46 kB)\n",
            "\u001b[K     |████████████████████████████████| 46 kB 3.9 MB/s \n",
            "\u001b[?25hRequirement already satisfied: gdown==4.4.0 in /usr/local/lib/python3.7/dist-packages (from flair) (4.4.0)\n",
            "Collecting mpld3==0.3\n",
            "  Downloading mpld3-0.3.tar.gz (788 kB)\n",
            "\u001b[K     |████████████████████████████████| 788 kB 62.9 MB/s \n",
            "\u001b[?25hRequirement already satisfied: regex in /usr/local/lib/python3.7/dist-packages (from flair) (2019.12.20)\n",
            "Collecting sentencepiece==0.1.95\n",
            "  Downloading sentencepiece-0.1.95-cp37-cp37m-manylinux2014_x86_64.whl (1.2 MB)\n",
            "\u001b[K     |████████████████████████████████| 1.2 MB 62.8 MB/s \n",
            "\u001b[?25hCollecting janome\n",
            "  Downloading Janome-0.4.2-py2.py3-none-any.whl (19.7 MB)\n",
            "\u001b[K     |████████████████████████████████| 19.7 MB 5.9 MB/s \n",
            "\u001b[?25hCollecting pptree\n",
            "  Downloading pptree-3.1.tar.gz (3.0 kB)\n",
            "Collecting huggingface-hub\n",
            "  Downloading huggingface_hub-0.6.0-py3-none-any.whl (84 kB)\n",
            "\u001b[K     |████████████████████████████████| 84 kB 3.4 MB/s \n",
            "\u001b[?25hCollecting langdetect\n",
            "  Downloading langdetect-1.0.9.tar.gz (981 kB)\n",
            "\u001b[K     |████████████████████████████████| 981 kB 44.8 MB/s \n",
            "\u001b[?25hCollecting deprecated>=1.2.4\n",
            "  Downloading Deprecated-1.2.13-py2.py3-none-any.whl (9.6 kB)\n",
            "Requirement already satisfied: scikit-learn>=0.21.3 in /usr/local/lib/python3.7/dist-packages (from flair) (1.0.2)\n",
            "Collecting konoha<5.0.0,>=4.0.0\n",
            "  Downloading konoha-4.6.5-py3-none-any.whl (20 kB)\n",
            "Collecting bpemb>=0.3.2\n",
            "  Downloading bpemb-0.3.3-py3-none-any.whl (19 kB)\n",
            "Collecting wikipedia-api\n",
            "  Downloading Wikipedia-API-0.5.4.tar.gz (18 kB)\n",
            "Requirement already satisfied: more-itertools in /usr/local/lib/python3.7/dist-packages (from flair) (8.13.0)\n",
            "Requirement already satisfied: python-dateutil>=2.6.1 in /usr/local/lib/python3.7/dist-packages (from flair) (2.8.2)\n",
            "Requirement already satisfied: matplotlib>=2.2.3 in /usr/local/lib/python3.7/dist-packages (from flair) (3.2.2)\n",
            "Requirement already satisfied: tabulate in /usr/local/lib/python3.7/dist-packages (from flair) (0.8.9)\n",
            "Requirement already satisfied: torch!=1.8,>=1.5.0 in /usr/local/lib/python3.7/dist-packages (from flair) (1.11.0+cu113)\n",
            "Collecting hyperopt>=0.2.7\n",
            "  Downloading hyperopt-0.2.7-py2.py3-none-any.whl (1.6 MB)\n",
            "\u001b[K     |████████████████████████████████| 1.6 MB 46.9 MB/s \n",
            "\u001b[?25hCollecting ftfy\n",
            "  Downloading ftfy-6.1.1-py3-none-any.whl (53 kB)\n",
            "\u001b[K     |████████████████████████████████| 53 kB 2.0 MB/s \n",
            "\u001b[?25hRequirement already satisfied: gensim>=3.4.0 in /usr/local/lib/python3.7/dist-packages (from flair) (3.6.0)\n",
            "Requirement already satisfied: tqdm>=4.26.0 in /usr/local/lib/python3.7/dist-packages (from flair) (4.64.0)\n",
            "Collecting transformers>=4.0.0\n",
            "  Downloading transformers-4.19.2-py3-none-any.whl (4.2 MB)\n",
            "\u001b[K     |████████████████████████████████| 4.2 MB 53.8 MB/s \n",
            "\u001b[?25hRequirement already satisfied: lxml in /usr/local/lib/python3.7/dist-packages (from flair) (4.2.6)\n",
            "Collecting conllu>=4.0\n",
            "  Downloading conllu-4.4.2-py2.py3-none-any.whl (15 kB)\n",
            "Requirement already satisfied: six in /usr/local/lib/python3.7/dist-packages (from gdown==4.4.0->flair) (1.15.0)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.7/dist-packages (from gdown==4.4.0->flair) (3.7.0)\n",
            "Requirement already satisfied: beautifulsoup4 in /usr/local/lib/python3.7/dist-packages (from gdown==4.4.0->flair) (4.6.3)\n",
            "Requirement already satisfied: requests[socks] in /usr/local/lib/python3.7/dist-packages (from gdown==4.4.0->flair) (2.23.0)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.7/dist-packages (from bpemb>=0.3.2->flair) (1.21.6)\n",
            "Requirement already satisfied: wrapt<2,>=1.10 in /usr/local/lib/python3.7/dist-packages (from deprecated>=1.2.4->flair) (1.14.1)\n",
            "Requirement already satisfied: smart-open>=1.2.1 in /usr/local/lib/python3.7/dist-packages (from gensim>=3.4.0->flair) (6.0.0)\n",
            "Requirement already satisfied: scipy>=0.18.1 in /usr/local/lib/python3.7/dist-packages (from gensim>=3.4.0->flair) (1.4.1)\n",
            "Requirement already satisfied: cloudpickle in /usr/local/lib/python3.7/dist-packages (from hyperopt>=0.2.7->flair) (1.3.0)\n",
            "Requirement already satisfied: networkx>=2.2 in /usr/local/lib/python3.7/dist-packages (from hyperopt>=0.2.7->flair) (2.6.3)\n",
            "Requirement already satisfied: future in /usr/local/lib/python3.7/dist-packages (from hyperopt>=0.2.7->flair) (0.16.0)\n",
            "Collecting py4j\n",
            "  Downloading py4j-0.10.9.5-py2.py3-none-any.whl (199 kB)\n",
            "\u001b[K     |████████████████████████████████| 199 kB 45.8 MB/s \n",
            "\u001b[?25hCollecting requests\n",
            "  Downloading requests-2.27.1-py2.py3-none-any.whl (63 kB)\n",
            "\u001b[K     |████████████████████████████████| 63 kB 1.9 MB/s \n",
            "\u001b[?25hCollecting overrides<4.0.0,>=3.0.0\n",
            "  Downloading overrides-3.1.0.tar.gz (11 kB)\n",
            "Collecting importlib-metadata<4.0.0,>=3.7.0\n",
            "  Downloading importlib_metadata-3.10.1-py3-none-any.whl (14 kB)\n",
            "Requirement already satisfied: typing-extensions>=3.6.4 in /usr/local/lib/python3.7/dist-packages (from importlib-metadata<4.0.0,>=3.7.0->konoha<5.0.0,>=4.0.0->flair) (4.2.0)\n",
            "Requirement already satisfied: zipp>=0.5 in /usr/local/lib/python3.7/dist-packages (from importlib-metadata<4.0.0,>=3.7.0->konoha<5.0.0,>=4.0.0->flair) (3.8.0)\n",
            "Requirement already satisfied: kiwisolver>=1.0.1 in /usr/local/lib/python3.7/dist-packages (from matplotlib>=2.2.3->flair) (1.4.2)\n",
            "Requirement already satisfied: cycler>=0.10 in /usr/local/lib/python3.7/dist-packages (from matplotlib>=2.2.3->flair) (0.11.0)\n",
            "Requirement already satisfied: pyparsing!=2.0.4,!=2.1.2,!=2.1.6,>=2.0.1 in /usr/local/lib/python3.7/dist-packages (from matplotlib>=2.2.3->flair) (3.0.9)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.7/dist-packages (from requests->bpemb>=0.3.2->flair) (2022.5.18.1)\n",
            "Requirement already satisfied: charset-normalizer~=2.0.0 in /usr/local/lib/python3.7/dist-packages (from requests->bpemb>=0.3.2->flair) (2.0.12)\n",
            "Requirement already satisfied: urllib3<1.27,>=1.21.1 in /usr/local/lib/python3.7/dist-packages (from requests->bpemb>=0.3.2->flair) (1.24.3)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.7/dist-packages (from requests->bpemb>=0.3.2->flair) (2.10)\n",
            "Requirement already satisfied: joblib>=0.11 in /usr/local/lib/python3.7/dist-packages (from scikit-learn>=0.21.3->flair) (1.1.0)\n",
            "Requirement already satisfied: threadpoolctl>=2.0.0 in /usr/local/lib/python3.7/dist-packages (from scikit-learn>=0.21.3->flair) (3.1.0)\n",
            "Collecting tokenizers!=0.11.3,<0.13,>=0.11.1\n",
            "  Downloading tokenizers-0.12.1-cp37-cp37m-manylinux_2_12_x86_64.manylinux2010_x86_64.whl (6.6 MB)\n",
            "\u001b[K     |████████████████████████████████| 6.6 MB 52.5 MB/s \n",
            "\u001b[?25hRequirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.7/dist-packages (from transformers>=4.0.0->flair) (21.3)\n",
            "Collecting pyyaml>=5.1\n",
            "  Downloading PyYAML-6.0-cp37-cp37m-manylinux_2_5_x86_64.manylinux1_x86_64.manylinux_2_12_x86_64.manylinux2010_x86_64.whl (596 kB)\n",
            "\u001b[K     |████████████████████████████████| 596 kB 53.4 MB/s \n",
            "\u001b[?25hRequirement already satisfied: wcwidth>=0.2.5 in /usr/local/lib/python3.7/dist-packages (from ftfy->flair) (0.2.5)\n",
            "Requirement already satisfied: PySocks!=1.5.7,>=1.5.6 in /usr/local/lib/python3.7/dist-packages (from requests->bpemb>=0.3.2->flair) (1.7.1)\n",
            "Building wheels for collected packages: mpld3, overrides, sqlitedict, langdetect, pptree, wikipedia-api\n",
            "  Building wheel for mpld3 (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for mpld3: filename=mpld3-0.3-py3-none-any.whl size=116702 sha256=6712d1b85cb2be2c11b1edc94fe5f3dcefbff76cbc74a0aa57a6d775e21248e5\n",
            "  Stored in directory: /root/.cache/pip/wheels/26/70/6a/1c79e59951a41b4045497da187b2724f5659ca64033cf4548e\n",
            "  Building wheel for overrides (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for overrides: filename=overrides-3.1.0-py3-none-any.whl size=10187 sha256=4c55c5a6a04cab7e346baa1c2ea045dc5fa15d1bccfc5865356658fa34838903\n",
            "  Stored in directory: /root/.cache/pip/wheels/3a/0d/38/01a9bc6e20dcfaf0a6a7b552d03137558ba1c38aea47644682\n",
            "  Building wheel for sqlitedict (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for sqlitedict: filename=sqlitedict-2.0.0-py3-none-any.whl size=15736 sha256=d0330ee9b099e18befc795597e3ceba9f3fde78deda47005a8bda30570409aa8\n",
            "  Stored in directory: /root/.cache/pip/wheels/96/dd/2e/0ed4a25cb73fc30c7ea8d10b50acb7226175736067e40a7ea3\n",
            "  Building wheel for langdetect (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for langdetect: filename=langdetect-1.0.9-py3-none-any.whl size=993242 sha256=753d77be94fe2aee71698b56d1d07e0d3b27077f71980437e696f48d76aa64b6\n",
            "  Stored in directory: /root/.cache/pip/wheels/c5/96/8a/f90c59ed25d75e50a8c10a1b1c2d4c402e4dacfa87f3aff36a\n",
            "  Building wheel for pptree (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for pptree: filename=pptree-3.1-py3-none-any.whl size=4629 sha256=976509a67e63302826b50892bdb82faad5f96a63ac90e8626f480d41720ea559\n",
            "  Stored in directory: /root/.cache/pip/wheels/9e/e8/7d/a9c3c19b4722608a0d8b05a38c36bc3f230c43becd2a46794b\n",
            "  Building wheel for wikipedia-api (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for wikipedia-api: filename=Wikipedia_API-0.5.4-py3-none-any.whl size=13477 sha256=bd5c72b1c15fa35294d1c24623e3c66121763549e9b8fccfae47aa325472d040\n",
            "  Stored in directory: /root/.cache/pip/wheels/d3/24/56/58ba93cf78be162451144e7a9889603f437976ef1ae7013d04\n",
            "Successfully built mpld3 overrides sqlitedict langdetect pptree wikipedia-api\n",
            "Installing collected packages: requests, pyyaml, importlib-metadata, tokenizers, sentencepiece, py4j, overrides, huggingface-hub, wikipedia-api, transformers, sqlitedict, segtok, pptree, mpld3, langdetect, konoha, janome, hyperopt, ftfy, deprecated, conllu, bpemb, flair\n",
            "  Attempting uninstall: requests\n",
            "    Found existing installation: requests 2.23.0\n",
            "    Uninstalling requests-2.23.0:\n",
            "      Successfully uninstalled requests-2.23.0\n",
            "  Attempting uninstall: pyyaml\n",
            "    Found existing installation: PyYAML 3.13\n",
            "    Uninstalling PyYAML-3.13:\n",
            "      Successfully uninstalled PyYAML-3.13\n",
            "  Attempting uninstall: importlib-metadata\n",
            "    Found existing installation: importlib-metadata 4.11.3\n",
            "    Uninstalling importlib-metadata-4.11.3:\n",
            "      Successfully uninstalled importlib-metadata-4.11.3\n",
            "  Attempting uninstall: hyperopt\n",
            "    Found existing installation: hyperopt 0.1.2\n",
            "    Uninstalling hyperopt-0.1.2:\n",
            "      Successfully uninstalled hyperopt-0.1.2\n",
            "\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
            "markdown 3.3.7 requires importlib-metadata>=4.4; python_version < \"3.10\", but you have importlib-metadata 3.10.1 which is incompatible.\n",
            "google-colab 1.0.0 requires requests~=2.23.0, but you have requests 2.27.1 which is incompatible.\n",
            "datascience 0.10.6 requires folium==0.2.1, but you have folium 0.8.3 which is incompatible.\u001b[0m\n",
            "Successfully installed bpemb-0.3.3 conllu-4.4.2 deprecated-1.2.13 flair-0.11.3 ftfy-6.1.1 huggingface-hub-0.6.0 hyperopt-0.2.7 importlib-metadata-3.10.1 janome-0.4.2 konoha-4.6.5 langdetect-1.0.9 mpld3-0.3 overrides-3.1.0 pptree-3.1 py4j-0.10.9.5 pyyaml-6.0 requests-2.27.1 segtok-1.5.11 sentencepiece-0.1.95 sqlitedict-2.0.0 tokenizers-0.12.1 transformers-4.19.2 wikipedia-api-0.5.4\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Ładowanie zbioru danych i słownika z etykietami.\n",
        "\n",
        "**Zadanie1: (1 punkt):** Stwórz słownik etykiet z wczytanego korpusu korzystając z funkcji `make_label_dictionary()`. W naszym zbiorze, etykiety do wykrycia występują w kolumnie `ner`, której identyfikator został zapisany w linijce 6. Tutorial: https://github.com/flairNLP/flair/blob/master/resources/docs/TUTORIAL_6_CORPUS.md może okazać się pomocny.\n",
        "\n",
        "Efektem działania powinna być lista etykiet np: \n",
        "`Dictionary with 20 tags: <unk>, Variable, Class, Application, User_Interface_Element, Code_Block, Language, Function, Data_Structure, Library, Data_Type, File_Type, File_Name, Version, HTML_XML_Tag, Device, Operating_System, Website, User_Name, Algorithm`"
      ],
      "metadata": {
        "id": "AyApRy6G7YQk"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from flair.datasets import NER_ENGLISH_STACKOVERFLOW    # zbiór otagowanych postów na Stacku\n",
        "\n",
        "corpus = NER_ENGLISH_STACKOVERFLOW().downsample(0.1)   # pobieramy korpus i zmniejszamy jego wielkość\n",
        "corpus.filter_empty_sentences()                         # usuwamy puste zdania\n",
        "\n",
        "label_type = 'ner'   # identyfikator pod którym możemy dostać typy etykiet\n",
        "label_dict = corpus.make_label_dictionary(label_type = label_type)    # TODO\n",
        "print('\\n\\nEtykiety do wykrycia')\n",
        "print(label_dict)"
      ],
      "metadata": {
        "id": "eK84adKF6GLr",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "0bfacf33-67b5-481c-c485-e6465250d205"
      },
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "2022-05-24 06:22:45,518 File train has 741 questions and 897 answers.\n",
            "2022-05-24 06:22:45,546 File test has 249 questions and 315 answers.\n",
            "2022-05-24 06:22:45,569 File dev has 247 questions and 289 answers.\n",
            "2022-05-24 06:22:45,573 Reading data from /root/.flair/datasets/ner_english_stackoverflow\n",
            "2022-05-24 06:22:45,576 Train: /root/.flair/datasets/ner_english_stackoverflow/train.txt\n",
            "2022-05-24 06:22:45,578 Dev: /root/.flair/datasets/ner_english_stackoverflow/dev.txt\n",
            "2022-05-24 06:22:45,581 Test: /root/.flair/datasets/ner_english_stackoverflow/test.txt\n",
            "2022-05-24 06:22:55,045 Filtering empty sentences\n",
            "2022-05-24 06:22:55,077 Corpus: 926 train + 294 dev + 311 test sentences\n",
            "2022-05-24 06:22:55,079 Computing label dictionary. Progress:\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "926it [00:00, 35020.61it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "2022-05-24 06:22:55,121 Dictionary created for label 'ner' with 20 values: Application (seen 134 times), Variable (seen 131 times), Class (seen 118 times), User_Interface_Element (seen 106 times), Code_Block (seen 99 times), Library (seen 79 times), Language (seen 73 times), Function (seen 62 times), Data_Structure (seen 52 times), Data_Type (seen 46 times), File_Name (seen 43 times), File_Type (seen 37 times), Version (seen 24 times), Operating_System (seen 20 times), HTML_XML_Tag (seen 15 times), Device (seen 13 times), Website (seen 10 times), User_Name (seen 8 times), Algorithm (seen 8 times)\n",
            "\n",
            "\n",
            "Etykiety do wykrycia\n",
            "Dictionary with 20 tags: <unk>, Application, Variable, Class, User_Interface_Element, Code_Block, Library, Language, Function, Data_Structure, Data_Type, File_Name, File_Type, Version, Operating_System, HTML_XML_Tag, Device, Website, User_Name, Algorithm\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Embeddingi\n",
        "\n",
        "W narzędziu Flair możemy bardzo prosto składać ze sobą różne embeddingi. \n",
        "\n",
        "**Zad2 (2 punkty):** Zapoznaj się z działaniem `StackedEmbeddings` opisanego w https://github.com/flairNLP/flair/blob/master/resources/docs/TUTORIAL_3_WORD_EMBEDDING.md i zbuduj embeddingi zawierające reprezentacje pochodzące zarówno z Glove jak i Flairowe, oparte na `news-forward`. "
      ],
      "metadata": {
        "id": "vlz60uuR83oR"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {
        "id": "yzCwq37iwFo4",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "2d614c64-6487-49f1-a359-789b8a9a2925"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Token[0]: \"The\"\n",
            "tensor([-0.0382, -0.2449,  0.7281,  ..., -0.0041, -0.0065,  0.0308])\n",
            "Token[1]: \"sky\"\n",
            "tensor([-0.1973, -0.1933,  0.4700,  ...,  0.0172,  0.0016, -0.0194])\n",
            "Token[2]: \"is\"\n",
            "tensor([-0.5426,  0.4148,  1.0322,  ..., -0.0017, -0.0132, -0.0189])\n",
            "Token[3]: \"blue\"\n",
            "tensor([ 0.0864,  0.7966, -0.0203,  ..., -0.0047, -0.0034, -0.0013])\n",
            "Token[4]: \".\"\n",
            "tensor([-0.3398,  0.2094,  0.4635,  ...,  0.0005, -0.0177,  0.0032])\n"
          ]
        }
      ],
      "source": [
        "from flair.embeddings import WordEmbeddings, StackedEmbeddings, FlairEmbeddings\n",
        "from flair.data import Sentence\n",
        "\n",
        "glove_embedding = WordEmbeddings('glove')\n",
        "\n",
        "flair_embedding_forward = FlairEmbeddings('news-forward')\n",
        "flair_embedding_backward = FlairEmbeddings('news-backward')\n",
        "\n",
        "embeddings = StackedEmbeddings([glove_embedding,\n",
        "                                flair_embedding_forward,\n",
        "                                flair_embedding_backward,])    # TODO\n",
        "\n",
        "sentence = Sentence('The sky is blue.')\n",
        "\n",
        "embeddings.embed(sentence)\n",
        "\n",
        "for token in sentence:\n",
        "    print(token)\n",
        "    print(token.embedding)"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Tagger i trainer\n",
        "\n",
        "**Zadanie 3 (2 punkty)** Bazując na treściach opisanych w https://github.com/flairNLP/flair/blob/master/resources/docs/TUTORIAL_7_TRAINING_A_MODEL.md przygotuj obiekt `SequenceTagger`, którego rozmiar wartswy ukrytej wyniesie 256. Do obiektu tego przekażemy stworzone wcześniej embeddingi, słownik `label_dict` i nazwę kolumny z etykietą ze zmiennej `label_type`. Ustawmy `use_crf` na True.\n",
        "\n",
        "Przygotuj obiekt `ModelTrainer`, który przyjmie zarówno nasz korpus jak i stworzony przed chwilą `SequenceTagger`."
      ],
      "metadata": {
        "id": "6Wxgw7Uc91e3"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from flair.models import SequenceTagger\n",
        "from flair.trainers import ModelTrainer\n",
        "\n",
        "\n",
        "tagger = SequenceTagger(hidden_size=256,\n",
        "                        embeddings=embeddings,\n",
        "                        tag_dictionary=label_dict,\n",
        "                        tag_type=label_type,\n",
        "                        use_crf=True)    # TODO\n",
        "                        \n",
        "trainer = ModelTrainer(tagger, corpus)   # TODO\n",
        "\n",
        "\n",
        "#stworzony trainer możemy zacząć trenować!\n",
        "trainer.train('resources/taggers/example-upos',\n",
        "              learning_rate=0.1,\n",
        "              mini_batch_size=32,\n",
        "              max_epochs=5)\n",
        "\n",
        "# a kiedy wytrenujemy, wczytujemy najlepszy model.\n",
        "model = SequenceTagger.load('resources/taggers/example-upos/final-model.pt')\n"
      ],
      "metadata": {
        "id": "ZqglzMPP92Fq",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "16b06e5c-4bdc-4714-84dd-e87a31840166"
      },
      "execution_count": 9,
      "outputs": [
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "2022-05-24 06:40:06,543 SequenceTagger predicts: Dictionary with 77 tags: O, S-Application, B-Application, E-Application, I-Application, S-Variable, B-Variable, E-Variable, I-Variable, S-Class, B-Class, E-Class, I-Class, S-User_Interface_Element, B-User_Interface_Element, E-User_Interface_Element, I-User_Interface_Element, S-Code_Block, B-Code_Block, E-Code_Block, I-Code_Block, S-Library, B-Library, E-Library, I-Library, S-Language, B-Language, E-Language, I-Language, S-Function, B-Function, E-Function, I-Function, S-Data_Structure, B-Data_Structure, E-Data_Structure, I-Data_Structure, S-Data_Type, B-Data_Type, E-Data_Type, I-Data_Type, S-File_Name, B-File_Name, E-File_Name, I-File_Name, S-File_Type, B-File_Type, E-File_Type, I-File_Type, S-Version\n",
            "2022-05-24 06:40:06,968 ----------------------------------------------------------------------------------------------------\n",
            "2022-05-24 06:40:06,973 Model: \"SequenceTagger(\n",
            "  (embeddings): StackedEmbeddings(\n",
            "    (list_embedding_0): WordEmbeddings(\n",
            "      'glove'\n",
            "      (embedding): Embedding(400001, 100)\n",
            "    )\n",
            "    (list_embedding_1): FlairEmbeddings(\n",
            "      (lm): LanguageModel(\n",
            "        (drop): Dropout(p=0.05, inplace=False)\n",
            "        (encoder): Embedding(300, 100)\n",
            "        (rnn): LSTM(100, 2048)\n",
            "        (decoder): Linear(in_features=2048, out_features=300, bias=True)\n",
            "      )\n",
            "    )\n",
            "    (list_embedding_2): FlairEmbeddings(\n",
            "      (lm): LanguageModel(\n",
            "        (drop): Dropout(p=0.05, inplace=False)\n",
            "        (encoder): Embedding(300, 100)\n",
            "        (rnn): LSTM(100, 2048)\n",
            "        (decoder): Linear(in_features=2048, out_features=300, bias=True)\n",
            "      )\n",
            "    )\n",
            "  )\n",
            "  (word_dropout): WordDropout(p=0.05)\n",
            "  (locked_dropout): LockedDropout(p=0.5)\n",
            "  (embedding2nn): Linear(in_features=4196, out_features=4196, bias=True)\n",
            "  (rnn): LSTM(4196, 256, batch_first=True, bidirectional=True)\n",
            "  (linear): Linear(in_features=512, out_features=79, bias=True)\n",
            "  (loss_function): ViterbiLoss()\n",
            "  (crf): CRF()\n",
            ")\"\n",
            "2022-05-24 06:40:06,978 ----------------------------------------------------------------------------------------------------\n",
            "2022-05-24 06:40:06,984 Corpus: \"Corpus: 926 train + 294 dev + 311 test sentences\"\n",
            "2022-05-24 06:40:06,987 ----------------------------------------------------------------------------------------------------\n",
            "2022-05-24 06:40:06,989 Parameters:\n",
            "2022-05-24 06:40:06,992  - learning_rate: \"0.100000\"\n",
            "2022-05-24 06:40:06,997  - mini_batch_size: \"32\"\n",
            "2022-05-24 06:40:06,998  - patience: \"3\"\n",
            "2022-05-24 06:40:07,000  - anneal_factor: \"0.5\"\n",
            "2022-05-24 06:40:07,002  - max_epochs: \"5\"\n",
            "2022-05-24 06:40:07,007  - shuffle: \"True\"\n",
            "2022-05-24 06:40:07,010  - train_with_dev: \"False\"\n",
            "2022-05-24 06:40:07,012  - batch_growth_annealing: \"False\"\n",
            "2022-05-24 06:40:07,013 ----------------------------------------------------------------------------------------------------\n",
            "2022-05-24 06:40:07,016 Model training base path: \"resources/taggers/example-upos\"\n",
            "2022-05-24 06:40:07,019 ----------------------------------------------------------------------------------------------------\n",
            "2022-05-24 06:40:07,023 Device: cpu\n",
            "2022-05-24 06:40:07,024 ----------------------------------------------------------------------------------------------------\n",
            "2022-05-24 06:40:07,026 Embeddings storage mode: cpu\n",
            "2022-05-24 06:40:07,027 ----------------------------------------------------------------------------------------------------\n",
            "2022-05-24 06:40:45,118 epoch 1 - iter 2/29 - loss 4.15472455 - samples/sec: 1.68 - lr: 0.100000\n",
            "2022-05-24 06:41:18,685 epoch 1 - iter 4/29 - loss 2.94792545 - samples/sec: 1.91 - lr: 0.100000\n",
            "2022-05-24 06:41:49,874 epoch 1 - iter 6/29 - loss 2.17662549 - samples/sec: 2.05 - lr: 0.100000\n",
            "2022-05-24 06:42:26,938 epoch 1 - iter 8/29 - loss 1.94219617 - samples/sec: 1.73 - lr: 0.100000\n",
            "2022-05-24 06:43:01,198 epoch 1 - iter 10/29 - loss 1.70754496 - samples/sec: 1.87 - lr: 0.100000\n",
            "2022-05-24 06:43:48,103 epoch 1 - iter 12/29 - loss 1.47106617 - samples/sec: 1.36 - lr: 0.100000\n",
            "2022-05-24 06:44:15,867 epoch 1 - iter 14/29 - loss 1.34354413 - samples/sec: 2.31 - lr: 0.100000\n",
            "2022-05-24 06:44:51,060 epoch 1 - iter 16/29 - loss 1.25234289 - samples/sec: 1.82 - lr: 0.100000\n",
            "2022-05-24 06:45:33,567 epoch 1 - iter 18/29 - loss 1.17973714 - samples/sec: 1.51 - lr: 0.100000\n",
            "2022-05-24 06:46:05,145 epoch 1 - iter 20/29 - loss 1.14641335 - samples/sec: 2.03 - lr: 0.100000\n",
            "2022-05-24 06:46:46,240 epoch 1 - iter 22/29 - loss 1.09103748 - samples/sec: 1.56 - lr: 0.100000\n",
            "2022-05-24 06:47:19,197 epoch 1 - iter 24/29 - loss 1.04662038 - samples/sec: 1.94 - lr: 0.100000\n",
            "2022-05-24 06:47:50,654 epoch 1 - iter 26/29 - loss 1.01384294 - samples/sec: 2.03 - lr: 0.100000\n",
            "2022-05-24 06:48:24,382 epoch 1 - iter 28/29 - loss 0.98283096 - samples/sec: 1.90 - lr: 0.100000\n",
            "2022-05-24 06:48:37,543 ----------------------------------------------------------------------------------------------------\n",
            "2022-05-24 06:48:37,546 EPOCH 1 done: loss 0.9687 - lr 0.100000\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 10/10 [02:14<00:00, 13.41s/it]"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "2022-05-24 06:50:51,651 Evaluating as a multi-label problem: False\n",
            "2022-05-24 06:50:51,705 DEV : loss 0.5247257351875305 - f1-score (micro avg)  0.0093\n",
            "2022-05-24 06:50:51,738 BAD EPOCHS (no improvement): 0\n",
            "2022-05-24 06:50:51,741 saving best model\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "2022-05-24 06:50:53,970 ----------------------------------------------------------------------------------------------------\n",
            "2022-05-24 06:51:02,854 epoch 2 - iter 2/29 - loss 0.64707669 - samples/sec: 7.21 - lr: 0.100000\n",
            "2022-05-24 06:51:09,853 epoch 2 - iter 4/29 - loss 0.58142981 - samples/sec: 9.15 - lr: 0.100000\n",
            "2022-05-24 06:51:17,761 epoch 2 - iter 6/29 - loss 0.60909703 - samples/sec: 8.10 - lr: 0.100000\n",
            "2022-05-24 06:51:24,741 epoch 2 - iter 8/29 - loss 0.63768047 - samples/sec: 9.17 - lr: 0.100000\n",
            "2022-05-24 06:51:31,920 epoch 2 - iter 10/29 - loss 0.61492100 - samples/sec: 8.92 - lr: 0.100000\n",
            "2022-05-24 06:51:40,542 epoch 2 - iter 12/29 - loss 0.61902057 - samples/sec: 7.43 - lr: 0.100000\n",
            "2022-05-24 06:51:47,535 epoch 2 - iter 14/29 - loss 0.60523311 - samples/sec: 9.16 - lr: 0.100000\n",
            "2022-05-24 06:51:55,470 epoch 2 - iter 16/29 - loss 0.59588103 - samples/sec: 8.07 - lr: 0.100000\n",
            "2022-05-24 06:52:04,928 epoch 2 - iter 18/29 - loss 0.58926394 - samples/sec: 6.77 - lr: 0.100000\n",
            "2022-05-24 06:52:11,307 epoch 2 - iter 20/29 - loss 0.57206614 - samples/sec: 10.04 - lr: 0.100000\n",
            "2022-05-24 06:52:18,811 epoch 2 - iter 22/29 - loss 0.57346100 - samples/sec: 8.53 - lr: 0.100000\n",
            "2022-05-24 06:52:26,014 epoch 2 - iter 24/29 - loss 0.57369687 - samples/sec: 8.89 - lr: 0.100000\n",
            "2022-05-24 06:52:32,473 epoch 2 - iter 26/29 - loss 0.57110290 - samples/sec: 9.91 - lr: 0.100000\n",
            "2022-05-24 06:52:38,957 epoch 2 - iter 28/29 - loss 0.56814762 - samples/sec: 9.88 - lr: 0.100000\n",
            "2022-05-24 06:52:44,594 ----------------------------------------------------------------------------------------------------\n",
            "2022-05-24 06:52:44,598 EPOCH 2 done: loss 0.5642 - lr 0.100000\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 10/10 [00:08<00:00,  1.18it/s]"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "2022-05-24 06:52:53,107 Evaluating as a multi-label problem: False\n",
            "2022-05-24 06:52:53,133 DEV : loss 0.5057647824287415 - f1-score (micro avg)  0.005\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "2022-05-24 06:52:53,165 BAD EPOCHS (no improvement): 1\n",
            "2022-05-24 06:52:53,172 ----------------------------------------------------------------------------------------------------\n",
            "2022-05-24 06:52:58,248 epoch 3 - iter 2/29 - loss 0.42588456 - samples/sec: 12.62 - lr: 0.100000\n",
            "2022-05-24 06:53:06,518 epoch 3 - iter 4/29 - loss 0.45256730 - samples/sec: 7.74 - lr: 0.100000\n",
            "2022-05-24 06:53:14,713 epoch 3 - iter 6/29 - loss 0.47194233 - samples/sec: 7.81 - lr: 0.100000\n",
            "2022-05-24 06:53:20,529 epoch 3 - iter 8/29 - loss 0.45292996 - samples/sec: 11.01 - lr: 0.100000\n",
            "2022-05-24 06:53:27,899 epoch 3 - iter 10/29 - loss 0.49253507 - samples/sec: 8.69 - lr: 0.100000\n",
            "2022-05-24 06:53:36,018 epoch 3 - iter 12/29 - loss 0.49896446 - samples/sec: 7.89 - lr: 0.100000\n",
            "2022-05-24 06:53:42,655 epoch 3 - iter 14/29 - loss 0.50348582 - samples/sec: 9.65 - lr: 0.100000\n",
            "2022-05-24 06:53:50,656 epoch 3 - iter 16/29 - loss 0.51524313 - samples/sec: 8.00 - lr: 0.100000\n",
            "2022-05-24 06:53:58,977 epoch 3 - iter 18/29 - loss 0.51252009 - samples/sec: 7.69 - lr: 0.100000\n",
            "2022-05-24 06:54:04,859 epoch 3 - iter 20/29 - loss 0.50368255 - samples/sec: 10.89 - lr: 0.100000\n",
            "2022-05-24 06:54:12,757 epoch 3 - iter 22/29 - loss 0.50143983 - samples/sec: 8.11 - lr: 0.100000\n",
            "2022-05-24 06:54:21,242 epoch 3 - iter 24/29 - loss 0.50518799 - samples/sec: 7.55 - lr: 0.100000\n",
            "2022-05-24 06:54:26,178 epoch 3 - iter 26/29 - loss 0.50990722 - samples/sec: 12.97 - lr: 0.100000\n",
            "2022-05-24 06:54:33,127 epoch 3 - iter 28/29 - loss 0.51723220 - samples/sec: 9.21 - lr: 0.100000\n",
            "2022-05-24 06:54:37,467 ----------------------------------------------------------------------------------------------------\n",
            "2022-05-24 06:54:37,469 EPOCH 3 done: loss 0.5130 - lr 0.100000\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 10/10 [00:08<00:00,  1.16it/s]"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "2022-05-24 06:54:46,073 Evaluating as a multi-label problem: False\n",
            "2022-05-24 06:54:46,100 DEV : loss 0.45791885256767273 - f1-score (micro avg)  0.1157\n",
            "2022-05-24 06:54:46,134 BAD EPOCHS (no improvement): 0\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "2022-05-24 06:54:46,137 saving best model\n",
            "2022-05-24 06:54:48,030 ----------------------------------------------------------------------------------------------------\n",
            "2022-05-24 06:54:55,916 epoch 4 - iter 2/29 - loss 0.48340531 - samples/sec: 8.12 - lr: 0.100000\n",
            "2022-05-24 06:55:02,272 epoch 4 - iter 4/29 - loss 0.49901316 - samples/sec: 10.07 - lr: 0.100000\n",
            "2022-05-24 06:55:10,238 epoch 4 - iter 6/29 - loss 0.49237240 - samples/sec: 8.04 - lr: 0.100000\n",
            "2022-05-24 06:55:16,529 epoch 4 - iter 8/29 - loss 0.46253946 - samples/sec: 10.18 - lr: 0.100000\n",
            "2022-05-24 06:55:25,452 epoch 4 - iter 10/29 - loss 0.43548913 - samples/sec: 7.17 - lr: 0.100000\n",
            "2022-05-24 06:55:32,655 epoch 4 - iter 12/29 - loss 0.43043566 - samples/sec: 8.89 - lr: 0.100000\n",
            "2022-05-24 06:55:41,462 epoch 4 - iter 14/29 - loss 0.43581303 - samples/sec: 7.27 - lr: 0.100000\n",
            "2022-05-24 06:55:51,300 epoch 4 - iter 16/29 - loss 0.45158674 - samples/sec: 6.51 - lr: 0.100000\n",
            "2022-05-24 06:55:58,680 epoch 4 - iter 18/29 - loss 0.46064042 - samples/sec: 8.68 - lr: 0.100000\n",
            "2022-05-24 06:56:06,354 epoch 4 - iter 20/29 - loss 0.46283840 - samples/sec: 8.34 - lr: 0.100000\n",
            "2022-05-24 06:56:13,796 epoch 4 - iter 22/29 - loss 0.46352846 - samples/sec: 8.60 - lr: 0.100000\n",
            "2022-05-24 06:56:19,347 epoch 4 - iter 24/29 - loss 0.47158011 - samples/sec: 11.54 - lr: 0.100000\n",
            "2022-05-24 06:56:25,306 epoch 4 - iter 26/29 - loss 0.47287127 - samples/sec: 10.75 - lr: 0.100000\n",
            "2022-05-24 06:56:31,678 epoch 4 - iter 28/29 - loss 0.46918133 - samples/sec: 10.05 - lr: 0.100000\n",
            "2022-05-24 06:56:34,190 ----------------------------------------------------------------------------------------------------\n",
            "2022-05-24 06:56:34,193 EPOCH 4 done: loss 0.4646 - lr 0.100000\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 10/10 [00:08<00:00,  1.17it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "2022-05-24 06:56:42,783 Evaluating as a multi-label problem: False\n",
            "2022-05-24 06:56:42,807 DEV : loss 0.42697325348854065 - f1-score (micro avg)  0.1587\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "2022-05-24 06:56:42,841 BAD EPOCHS (no improvement): 0\n",
            "2022-05-24 06:56:42,845 saving best model\n",
            "2022-05-24 06:56:44,755 ----------------------------------------------------------------------------------------------------\n",
            "2022-05-24 06:56:54,854 epoch 5 - iter 2/29 - loss 0.43012808 - samples/sec: 6.34 - lr: 0.100000\n",
            "2022-05-24 06:57:01,977 epoch 5 - iter 4/29 - loss 0.40638431 - samples/sec: 8.99 - lr: 0.100000\n",
            "2022-05-24 06:57:09,050 epoch 5 - iter 6/29 - loss 0.39074498 - samples/sec: 9.05 - lr: 0.100000\n",
            "2022-05-24 06:57:14,268 epoch 5 - iter 8/29 - loss 0.39305928 - samples/sec: 12.27 - lr: 0.100000\n",
            "2022-05-24 06:57:24,306 epoch 5 - iter 10/29 - loss 0.39523775 - samples/sec: 6.38 - lr: 0.100000\n",
            "2022-05-24 06:57:32,679 epoch 5 - iter 12/29 - loss 0.39741982 - samples/sec: 7.65 - lr: 0.100000\n",
            "2022-05-24 06:57:39,024 epoch 5 - iter 14/29 - loss 0.39235670 - samples/sec: 10.09 - lr: 0.100000\n",
            "2022-05-24 06:57:44,415 epoch 5 - iter 16/29 - loss 0.39792278 - samples/sec: 11.88 - lr: 0.100000\n",
            "2022-05-24 06:57:52,432 epoch 5 - iter 18/29 - loss 0.39846983 - samples/sec: 7.99 - lr: 0.100000\n",
            "2022-05-24 06:57:58,813 epoch 5 - iter 20/29 - loss 0.41553357 - samples/sec: 10.04 - lr: 0.100000\n",
            "2022-05-24 06:58:05,941 epoch 5 - iter 22/29 - loss 0.42428375 - samples/sec: 8.98 - lr: 0.100000\n",
            "2022-05-24 06:58:14,978 epoch 5 - iter 24/29 - loss 0.43248804 - samples/sec: 7.08 - lr: 0.100000\n",
            "2022-05-24 06:58:22,966 epoch 5 - iter 26/29 - loss 0.43863909 - samples/sec: 8.02 - lr: 0.100000\n",
            "2022-05-24 06:58:29,240 epoch 5 - iter 28/29 - loss 0.44055868 - samples/sec: 10.20 - lr: 0.100000\n",
            "2022-05-24 06:58:33,205 ----------------------------------------------------------------------------------------------------\n",
            "2022-05-24 06:58:33,207 EPOCH 5 done: loss 0.4318 - lr 0.100000\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 10/10 [00:08<00:00,  1.17it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "2022-05-24 06:58:41,776 Evaluating as a multi-label problem: False\n",
            "2022-05-24 06:58:41,802 DEV : loss 0.4075446128845215 - f1-score (micro avg)  0.1744\n",
            "2022-05-24 06:58:41,836 BAD EPOCHS (no improvement): 0\n",
            "2022-05-24 06:58:41,839 saving best model\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "2022-05-24 06:58:45,645 ----------------------------------------------------------------------------------------------------\n",
            "2022-05-24 06:58:45,653 loading file resources/taggers/example-upos/best-model.pt\n",
            "2022-05-24 06:58:47,027 SequenceTagger predicts: Dictionary with 79 tags: O, S-Application, B-Application, E-Application, I-Application, S-Variable, B-Variable, E-Variable, I-Variable, S-Class, B-Class, E-Class, I-Class, S-User_Interface_Element, B-User_Interface_Element, E-User_Interface_Element, I-User_Interface_Element, S-Code_Block, B-Code_Block, E-Code_Block, I-Code_Block, S-Library, B-Library, E-Library, I-Library, S-Language, B-Language, E-Language, I-Language, S-Function, B-Function, E-Function, I-Function, S-Data_Structure, B-Data_Structure, E-Data_Structure, I-Data_Structure, S-Data_Type, B-Data_Type, E-Data_Type, I-Data_Type, S-File_Name, B-File_Name, E-File_Name, I-File_Name, S-File_Type, B-File_Type, E-File_Type, I-File_Type, S-Version\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 10/10 [02:21<00:00, 14.20s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "2022-05-24 07:01:09,399 Evaluating as a multi-label problem: False\n",
            "2022-05-24 07:01:09,427 0.3306\t0.112\t0.1674\t0.1026\n",
            "2022-05-24 07:01:09,428 \n",
            "Results:\n",
            "- F-score (micro) 0.1674\n",
            "- F-score (macro) 0.0589\n",
            "- Accuracy 0.1026\n",
            "\n",
            "By class:\n",
            "                        precision    recall  f1-score   support\n",
            "\n",
            "                 Class     0.4098    0.4310    0.4202        58\n",
            "User_Interface_Element     0.5333    0.1569    0.2424        51\n",
            "           Application     0.2000    0.0789    0.1132        38\n",
            "               Library     0.0000    0.0000    0.0000        33\n",
            "              Variable     0.2000    0.0370    0.0625        27\n",
            "              Function     0.0000    0.0000    0.0000        27\n",
            "            Code_Block     0.0000    0.0000    0.0000        23\n",
            "              Language     0.2000    0.2500    0.2222        12\n",
            "        Data_Structure     0.0000    0.0000    0.0000        23\n",
            "             File_Name     0.0000    0.0000    0.0000        18\n",
            "             File_Type     0.0000    0.0000    0.0000         9\n",
            "             Data_Type     0.0000    0.0000    0.0000        10\n",
            "                Device     0.0000    0.0000    0.0000         6\n",
            "               Version     0.0000    0.0000    0.0000         6\n",
            "          HTML_XML_Tag     0.0000    0.0000    0.0000         5\n",
            "      Operating_System     0.0000    0.0000    0.0000         5\n",
            "               Website     0.0000    0.0000    0.0000         3\n",
            "             User_Name     0.0000    0.0000    0.0000         3\n",
            "\n",
            "             micro avg     0.3306    0.1120    0.1674       357\n",
            "             macro avg     0.0857    0.0530    0.0589       357\n",
            "          weighted avg     0.1859    0.1120    0.1271       357\n",
            "\n",
            "2022-05-24 07:01:09,431 ----------------------------------------------------------------------------------------------------\n",
            "2022-05-24 07:01:09,440 loading file resources/taggers/example-upos/final-model.pt\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "2022-05-24 07:01:10,416 SequenceTagger predicts: Dictionary with 79 tags: O, S-Application, B-Application, E-Application, I-Application, S-Variable, B-Variable, E-Variable, I-Variable, S-Class, B-Class, E-Class, I-Class, S-User_Interface_Element, B-User_Interface_Element, E-User_Interface_Element, I-User_Interface_Element, S-Code_Block, B-Code_Block, E-Code_Block, I-Code_Block, S-Library, B-Library, E-Library, I-Library, S-Language, B-Language, E-Language, I-Language, S-Function, B-Function, E-Function, I-Function, S-Data_Structure, B-Data_Structure, E-Data_Structure, I-Data_Structure, S-Data_Type, B-Data_Type, E-Data_Type, I-Data_Type, S-File_Name, B-File_Name, E-File_Name, I-File_Name, S-File_Type, B-File_Type, E-File_Type, I-File_Type, S-Version\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Predykcja z udziałem modelu\n",
        "\n",
        "Jeśli model został wytrenowany, poniżej znajdziemy fragment kodu, który może wykryć encje w zdaniach."
      ],
      "metadata": {
        "id": "lxrd6m0H_-SJ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from flair.data import Sentence\n",
        "\n",
        "# Jeśli nasz model się wyuczył, powinien wykryć Python jako język.\n",
        "# Uwaga, ponieważ pracujemy na niewielkim podzbiorze zbioru danych (downsample(0.1) próbkuje 10%), \n",
        "# otrzymywane wyniki mogą być kiepskiej jakości, najlepiej zwiększyść ilość danych \n",
        "# jeśli pracujemy w domu.\n",
        "sentence = Sentence('huge files can be opened from Python 3.')   # stwórz obiekt zdania\n",
        "model.predict(sentence)                                         # wykryj encje nazwane\n",
        "print(sentence.to_tagged_string())                              # wyświetl zdanie i wykryte w nim encje"
      ],
      "metadata": {
        "id": "Koq76zqawM3P",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "14c909cc-48f3-4508-f4bd-b85d7047dc2e"
      },
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Sentence: \"huge files can be opened from Python 3 .\" → [\"Python\"/Language]\n"
          ]
        }
      ]
    }
  ]
}